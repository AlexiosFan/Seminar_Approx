\documentclass{beamer}

\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{marvosym}

\newcommand*{\brk}{\\[10pt]}
\newcommand*{\doublebrk}{\\[10pt]}

\title{Approximation: Greedy and Local Search}

\author{Zixuan Fan}
\institute{Technische Universität München}

\date{July 2024}

\begin{document}
\begin{frame}
    \titlepage   
\end{frame}

\begin{frame}
    \frametitle{Agenda}
    \begin{enumerate}
        \item Introduction
        \item Scheduling Problems
            \begin{itemize}
                \item Scheduling with deadlines on a Single machine
                \item Scheduling on Multiple Machines 
            \end{itemize}
        \item Graph Problems 
            \begin{itemize}
                \item K-center Problem 
                \item Travelling Salesman Problem
            \end{itemize}
        \item Conclusion
    \end{enumerate}
\end{frame}

\begin{frame}
    \frametitle{Purpose of Approximation}
    \begin{itemize}
        \item<1-> Some problems not efficiently solvable: NP-hardness
        \item<2-> Can we find a flawed solution?
        \item<3-> How flawed/good is this solution?
        \item<4-> What is the limit of this flawed solution?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Quick Recap: Approximation Ratio}
    $Opt^*$: the optimal solution \\ 
    $Opt$: the suboptimal solution we compute \\[10pt]
    For minimization problems, we have
    \begin{align*}
        \alpha = \dfrac{|Opt|}{|Opt^*|} > 1
    \end{align*}
    And for maximization problems
    \begin{align*}
        \alpha = \dfrac{|Opt|}{|Opt^*|} < 1
    \end{align*}
\end{frame}

\begin{frame}
    \frametitle{Techniques in Approximation}
    \begin{enumerate}
        \item<1-> Randomization: MAXSAT, MAXCUT
        \item<2-> Dynamic Programming: Knapsack, Bin Packing
        \item<3-> Linear \& Integer Programming: Primal-Dual, Semidefinite Program 
        \item<4-> \color{red} Greedy \& Local Search \color{black}
    \end{enumerate}
\end{frame}

\begin{frame}{Greedy and Local Search}
    \begin{itemize}
        \item<1-> Both strategies attempt to make the best decision
        \item<2-> Greedy algorithms forms a solution step by step 
        \item<3-> Local Search starts search from an arbitrary solution
    \end{itemize}
\end{frame}


\begin{frame}{Scheduling with deadlines on a Single machine}
    \textbf{Problem Statement: } Given $n$ jobs to be processed on a single machine. 
    How can we schedule them such that they will finish as early as possible. \brk 
    \begin{itemize}
        \item What if there is not deadline?
        \item How do we define earlieness/lateness?
    \end{itemize}
\end{frame}


\begin{frame}{Scheduling with deadlines on a Single machine - Formal Definition}
Suppose job $j$ is finished at time $C_j$, the lateness is 
\begin{align*}
    L_j := C_j - d_j 
\end{align*}
The lateness of all jobs is 
\begin{align*}
    L_{max} = \max_{i \in [n]} L_i
\end{align*}
\textbf{Input:} $n$ jobs with release time $r_j$, processing time $p_j$, and deadline $d_j$. \brk 
\textbf{Output:} a schedule such that $L_{max}$ is minimized.
\end{frame}

\begin{frame}{Algorithm - Intuition}
    If the job $j$ is finished before the deadline we don't get penalty for it, so \dots 
    \begin{enumerate}
        \item<1-> What if we always choose the job with the earliest deadlines 
        \item<2-> But, we may have deal with negative values. 
        \item<3> So all deadlines are negative (by assumption).
    \end{enumerate}
\end{frame}

\begin{frame}{Algorithm - Analysis}
    We start with an observation. 
    Let $S$ be a set of jobs,
    \begin{itemize}
        \item $r(S) := \min_{j \in S} r_j$ 
        \item $p(S) := \sum_{j \in S} p_j$ 
        \item $d(S) := \max_{j \in S} d_j$
    \end{itemize}
    We claim that
    \begin{align*}
        L_{max}^* \geq r(S) + p(S) - d(S)
    \end{align*}
    This is proven by considering the optimal schedule.
\end{frame}

\begin{frame}{Algorithm - Analysis}
    \begin{align*}
        L_{max}^* \geq r(S) + p(S) - d(S)
    \end{align*}
    This leads directly to 
    \begin{align*}
        L_{max}^* \geq r({j}) + p({j}) - d({j}) \geq -d_j
    \end{align*}
    where $j$ is the job that leads to the maximal lateness. 
\end{frame}

\begin{frame}{Algorithm - Analysis}
    \begin{align*}
        L_{max}^* \geq -d_j
    \end{align*}
    Recall $L_{max} = C_j - d_j$, it suffices to show
    \begin{align*}
        L_{max}^* \geq C_j
    \end{align*}
\end{frame}

\begin{frame}{Algorithm - Analysis}
    We start with an ideal scenario: all jobs are released at time $t = 0$. We have 
    \begin{itemize}
        \item $r(S) = 0$ 
        \item $p(S) = C_j$ 
        \item $d(S) < 0$, by assumption
    \end{itemize}
    From lemma it follows that 
    \begin{align*}
        L_{max}^* \geq r(S) + p(S) - d(S) \geq p(S) = C_j
    \end{align*}
    \pause
    \color{red} How about the general cases? \color{black}
\end{frame}

\begin{frame}{Algorithm - Analysis}
    \color{red} How about the general cases? \color{black} 
    \begin{itemize}
        \item<1-> We consider it in a way of calculus
        \item<2-> Find the time $t$ such that $[t, C_j]$ has no idle time 
        \item<3-> Denote jobs processed in this interval with $S$.
        \item<4-> $r(S) = t$, $p(S) = C_j - t$ 
        \item<5> Thus $C_j = r(S) + p(S) \leq L_{max}^*$ 
    \end{itemize}
\end{frame}

\begin{frame}{Algorithm - Analysis} 
    Summarizing two results $L_{max}^* \geq -d_j$ and $L_{max}^* \geq C_j$, we obtain
    \begin{align*}
        L_{max} = C_j - d_j \leq 2L_{max}^*
    \end{align*}
\end{frame} 

\begin{frame}{Scheduling on Identical Paralle Machines}
    \textbf{Problem Statement: } Given $n$ jobs to be processed on $k$ 
    machines, How can we schedule them such that they will finish as early as possible. \brk 
    \begin{itemize}
        \item What if there is not deadline?
        \item How do we define earlieness/lateness?
    \end{itemize}
\end{frame}

\begin{frame}{Scheduling on Identical Paralle Machines - Formal Definition}
    More machines $\implies$ more complexity \brk 
    So the problem is \textbf{NP-hard} even if \brk 
    \ \ \ \ we don't consider \color{red} release time \color{black} and \color{red} deadlines \color{black}
\end{frame}

\begin{frame}{Scheduling on Identical Paralle Machines - Formal Definition}
    \textbf{Input:} $n$ jobs with processing time $p_j$ and $k$ machines \brk 
    \textbf{Output:} A schedule that minimizes 
    \begin{align*}
        \max_{j \in [n]} C_j 
    \end{align*}
    where $C_j$ is the completion time of job $j$.
\end{frame}

\begin{frame}{Algorithm - Local Search}
    \textbf{Recap:} Local search 
    \begin{itemize}
        \item<1-3> starts with a valid solution 
        \item<2-3> searches greedily until 
        \item<3> no better strategy can be made 
        \item<4> How do we find a valid solution?
        \item<4> How to make greedy strategy?
    \end{itemize}
\end{frame}

\begin{frame}{Algorithm - Local Search}
    \textbf{Recap:} Local search 
    \begin{itemize}
        \item<1-> How do we find a valid solution?
        \item<2-> \color{red} Finish all jobs in one machine. \color{black}
        \item<1-> How to make greedy strategy?
        \item<3-> \color{red} Separate those jobs to other machines. \color{black}
    \end{itemize}
\end{frame}

\begin{frame}{Local Search - Seperation of Jobs}
    \begin{itemize}
        \item Pick the last job $j$ at the machine $M$ with the latest running time
        \item Let $t$ be the processing time of all other jobs on $M$
        \item Find another machine $M'$ such that $t' < t$ is minimized
        \item Add $j$ to $M'$
    \end{itemize}
    \pause 
    But, can we go into \color{red} LOOPs \color{black}?
\end{frame}

\begin{frame}{Local Search - Analysis}
    We show that a job is only assigned \textbf{once} in our local search algorithm. \brk 
    \textbf{Suppose} that a job $j$ on machine $M$ is assigned for a \textbf{second} time. \brk \pause
    $\implies$ machine $M$ has the latest running time \brk \pause
    $\implies$ there is another machine $M'$ such that $t' < t$ \brk \pause 
    \textbf{BUT}: by our strategy $t$ has to be minimal when $j$ was assigned at an earlier step. \brk \pause 
    \ \ \ \ We denote completion time on $M'$ at this step as $t'_0$, it holds 
    \begin{align*}
        t' \geq t'_0 \geq t \ \mbox{\Lightning}
    \end{align*}  
\end{frame}

\begin{frame}{Local Search - Analysis}
    What about the approximation ratio? \brk \pause 
    \begin{itemize}
        \item Completion time on each machine should be close to mean: $$\dfrac{\sum_{j \in [n]}p_j}{n}$$
        \item It's also the case for the optimal solution, and $$|Opt^*| \geq \dfrac{\sum_{j \in [n]}p_j}{k}$$
        \item We show $$|Opt| \leq \dfrac{2\sum_{j \in [n]}p_j}{k} \leq 2|Opt^*|$$
    \end{itemize}
\end{frame}

\begin{frame}{Local Search - Analysis}
    We show $$|Opt| \leq \dfrac{2\sum_{j \in [n]}p_j}{k}$$ 
    \begin{itemize}
        \item Consider the machine $M$ with the longest completion time 
        \item Job $j$ that completes last with processing time $p_j$ 
        \item All other jobs completes at $t$.
    \end{itemize}
    We have $$|Opt| = t + p_j$$ and we may witness 
    \begin{align*}
        t &\leq  \dfrac{\sum_{j \in [n]}p_j}{k} \\ 
        p_j &\leq  \dfrac{\sum_{j \in [n]}p_j}{k}
    \end{align*}
\end{frame}

\begin{frame}{Algorithm - Greedy and More}
    \begin{itemize}
        \item There exists greedy algorithm that solves problem with $\alpha = 2, \dfrac{4}{3}$
        \item With rounding and DP, the problem can be approximated with $\alpha = 1 +\epsilon$ for any $\epsilon > 0$
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{K-Center Problem}
    \textbf{Problem Statement:} Given $n$ points in a space, 
    choose $k$ centers from them such that the sum of distances between 
    each point and its nearest neighbor is minimized. 
\end{frame}

\begin{frame}{K-Center Problem - Formal Definition}
    $d(p, q)$: distance between $p, q$ \\ 
    $d(p, S) := \min_{q \in S} d(p, q)$ \\
    \textbf{Input:} $S, k$ \\
    \textbf{Output:} $C \subseteq S$ s.t. $|C| = k$ and  $\sum_{p \in S} d(p, S)$ 
    is minimized \\[20pt]
    \pause 
    \textbf{What is the distance function? \\ Or what property does the distance function have?}
\end{frame}

% present an example (from book?)

\begin{frame}{Algorithm - Intuition}
    How do we search \textbf{greedily}? \\[10pt]
    If we have a temporary center $|C| < k$, how to build $|C'| = |C| + 1$?
\end{frame}

\begin{frame}{Algorithm - Description}
    Find $v \in S \backslash C$ s.t. $d(v, C)$ is maximized. \brk
    $C' = C \cup \{v\}$ \brk
    \pause
    What is the cost per iteration? \pause $O(|S| \cdot |S \backslash V|) = O(n^2)$
\end{frame}

\begin{frame}{Algorithm - Description}
    But, what is $C$ at the beginning of the iteration? 
    \pause 
    \begin{enumerate}
        \item The center of all points? $\implies$ Needs another $O(n^2)$ cost 
        \item Any arbitrary point $\implies$ Constant cost
    \end{enumerate}
    \pause
    Is the $O(n^2)$ cost worth it? We will discuss it later.
\end{frame}

\begin{frame}{Analysis}
    \textbf{Quadratic} cost
    \pause\brk
    \textbf{Approximation ratio?}
\end{frame}

\begin{frame}{Approximation ratio: Base}
    Suppose each optimal cluster contains exactly one center by our algorithm.\brk
    \pause
    If all points in this cluster is covered by the cluster of this new center
    \begin{align*}
        r \leq 2r^*        
    \end{align*}
    If they are not covered $\implies$ a shorter radius is ok. \brk
    \pause 
    But guarantees $\alpha = \dfrac{r}{r^*} = 2$ 
\end{frame}

\begin{frame}{Approximation ratio: General}
    What if one optimal cluster contains two or even more centers? \brk 
    This is solve by our greediness. \textbf{HOW?}
\end{frame}

\begin{frame}{Approximation ratio: Improvement?}
    Can we have a better approximation? \brk
    Sadly, NO
\end{frame}

% omit the reduction of dominating set due to time limitations
% But keep this part for TSP

\begin{frame}{Traverlling Salesman Problem(TSP)}
    \textbf{Problem Statement:} Given a complete weighted graph of $n$ vertices, find the round tour with the minimal cost. 
\end{frame}

\begin{frame}{TSP - Formal Definition}
    \textbf{Input:} $G = (V, d)$ \\
    \textbf{Output:} Path $\pi$ s.t. $\sum_{i = 1}^{n-1} w(\pi(1), \pi(2))$
    is minimized \\[20pt]
    \pause 
    \textbf{What is the distance function? \\ Or what property does the distance function have?}
\end{frame}

\begin{frame}{TSP-Limit of Approximation}
    \begin{enumerate}
        \item<1-3> No existent approximation for TSP in general 
        \item<2-3> If there was $\implies$ Hamilton-Cycle solvable in P!
        \item<3> But: metric distance can help us!
    \end{enumerate}
    \pause 
    Suppose for each vertice $u, v, w \in V$, triangular inequality holds
    \begin{align*}
        d(u, v) + d(v, w) \geq d(u, w)
    \end{align*}
\end{frame}

\begin{frame}{Algorithm - A bit help from Euler}
    \begin{itemize}
        \item<1-2> Minimum Spanning Tree(MST). The tree that connects all vertices with minimal edge cost.
        \item<2> Eulerian Graph: connected graph where all vertices have even degrees.
        \item<3-> What if we make a copy of MST?
        \item<4-> This is make a Eulerian Graph $\implies$ Not a round tour 
        \item<5-> What if we remove all but the first occurrences?
        \item<6-> This is a round tour!
    \end{itemize}
\end{frame}

\begin{frame}{Algorithm - A bit help from Euler}
    For the size of the tour:
    \begin{enumerate}
        \item $w_{MST} \leq w_{Opt^*}$: Round tour contains trees!
        \item $w_G \leq 2w{MST}$: triangular inequality
    \end{enumerate}
    $\implies w_G \leq 2w_{Opt^*}$ 
\end{frame}

\begin{frame}{Algorithm - A bit help from Christofide}
\begin{itemize}
    \item<1-> We can do the same trick to all Eulerian Graphs
    \item<2-> As long as it connects all vertices 
    \item<3-> How to make MST Eulerian?
    \item<4-> Make all vertices have \textbf{even} degrees
\end{itemize}
\end{frame}

\begin{frame}{Algorithm - A bit help from Christofide}
    \textbf{HOW?}
    \begin{enumerate}
        \item<1-> Connect all vertices with odd degrees
        \item<2-> How many vertices with odd degrees?
        \item<3-> Finding a perfect matching
        \item<4-> What is the cost? What is the size of the PM?
    \end{enumerate}
\end{frame}

\begin{frame}{Algorithm - A bit help from Christofide}
    For the size of the tour:
    \begin{enumerate}
        \item $w_{MST} \leq w_{Opt^*}$: see 1st part
        \item $w_{PM} \leq \dfrac{1}{2} w_{Opt^*}$:
        \item $w_{G} \leq w_{MST} + w{PM}$: traingular inequality
    \end{enumerate}
    $\implies w_{G} \leq \dfrac{3}{2} w_{Opt^*}$
\end{frame}

\begin{frame}{Limit of Approximation(Again)}
    Even if it is possible to do the approximation for metric TSP, we cannot do better than $\alpha < \dfrac{220}{219}$
    unless \textbf{P} $=$ \textbf{NP}
\end{frame}

\end{document}